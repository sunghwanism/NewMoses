{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "import torch\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from moses.vae import VAE\n",
    "from moses.vae_property import VAEPROPERTY\n",
    "from moses.vae.trainer import VAETrainer\n",
    "from moses.vae_property.trainer import VAEPROPERTYTrainer \n",
    "\n",
    "from moses.metrics import QED, SA, logP\n",
    "from moses.utils import get_mol\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import rdBase\n",
    "#from rdkit import RDLogger\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "rdBase.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../checkpoints/opimize_gpr/gpr_fit_ZINC250K_df.csv\")[:use_sample]\n",
    "test_df = pd.read_csv(\"../checkpoints/opimize_gpr/gpr_test_ZINC250K_df.csv\")\n",
    "start_df = pd.read_csv(\"../checkpoints/opimize_gpr/opt_start_ZINC250K_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'gpr train: {train_df.shape}')\n",
    "print(f'gpr test: {test_df.shape}')\n",
    "print(f'gpr start: {start_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'VAEProp_obj_w0.1'\n",
    "folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1\"\n",
    "config = torch.load(f'{folder_path}/vae_property_config.pt')\n",
    "vocab = torch.load(f'{folder_path}/vae_property_vocab.pt')\n",
    "\n",
    "print(f\"Use Selfies: {config.use_selfies}\")\n",
    "print(config.reg_prop_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SELFIES' if config.use_selfies else 'SMILES', 'logP', 'qed', 'SAS', 'obj']\n",
    "train_data = train_df[cols].values\n",
    "test_data = test_df[cols].values\n",
    "start_data = start_df[cols].values\n",
    "\n",
    "\n",
    "model_path = f'{folder_path}/vae_property_model_080.pt'\n",
    "\n",
    "\n",
    "model = VAEPROPERTY(vocab, config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "trainer = VAEPROPERTYTrainer(config)\n",
    "train_loader = trainer.get_dataloader(model, train_data, shuffle=False)\n",
    "test_loader = trainer.get_dataloader(model, test_data, shuffle=False)\n",
    "start_loader = trainer.get_dataloader(model, start_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x_list = []\n",
    "z_list = []\n",
    "mu_list = []\n",
    "logvar_list = []\n",
    "y_list = []\n",
    "\n",
    "\n",
    "# y_list = y_list.squeeze()\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    x_list.extend(x)\n",
    "    y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "    mu, logvar, z, _ = model.forward_encoder(x)\n",
    "    z_list.extend(z.detach().cpu().numpy())\n",
    "    mu_list.extend(mu.detach().cpu().numpy())\n",
    "    logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "y_list = np.array(y_list).squeeze()\n",
    "GP_train_y = y_list.reshape(-1, y_list.shape[-1])\n",
    "\n",
    "train_data_df = pd.DataFrame(GP_train_y, columns=['logP', 'qed', 'SAS', 'obj'])\n",
    "train_data_df = pd.concat([train_data_df , pd.DataFrame({'z': z_list, 'mu': mu_list, 'logvar': logvar_list})], axis=1)\n",
    "train_data_df.insert(0, 'SELFIES' if config.use_selfies else 'SMILES', [vocab.ids2string(point.cpu().detach().numpy()) for point in x_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_x_list = []\n",
    "test_z_list = []\n",
    "test_mu_list = []\n",
    "test_logvar_list = []\n",
    "test_y_list = []\n",
    "\n",
    "\n",
    "# y_list = y_list.squeeze()\n",
    "\n",
    "for step, batch in enumerate(test_loader):\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    test_x_list.extend(x)\n",
    "    test_y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "    mu, logvar, z, _ = model.forward_encoder(x)\n",
    "    test_z_list.extend(z.detach().cpu().numpy())\n",
    "    test_mu_list.extend(mu.detach().cpu().numpy())\n",
    "    test_logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "test_y_list = np.array(test_y_list).squeeze()\n",
    "GP_test_y = y_list.reshape(-1, test_y_list.shape[-1])\n",
    "\n",
    "test_data_df = pd.DataFrame(GP_test_y, columns=['logP', 'qed', 'SAS', 'obj'])\n",
    "test_data_df = pd.concat([test_data_df , pd.DataFrame({'z': test_z_list, 'mu': test_mu_list, 'logvar': test_logvar_list})], axis=1)\n",
    "test_data_df.insert(0, 'SELFIES' if config.use_selfies else 'SMILES', [vocab.ids2string(point.cpu().detach().numpy()) for point in test_x_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_Train_x = train_data_df.z.values\n",
    "GP_Test_x = test_data_df.z.values\n",
    "\n",
    "GP_Train_y = train_data_df['obj'].values\n",
    "GP_Test_y = test_data_df['obj'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: z\n",
    "# output: obj\n",
    "\n",
    "from moses.metrics import QED, SA, logP\n",
    "\n",
    "\n",
    "def objective_function(z): #ground truth\n",
    "    # kernel = C * RBF(RBF_length_scale)\n",
    "    # gp = GaussianProcessRegressor(kernel=kernel)\n",
    "    # gp.fit(GP_train_x, GP_train_y)\n",
    "    # predictions = gp.predict(GP_test_x)\n",
    "    \n",
    "    gen = model.sample(len(z), max_len=100, z=z, temp=1.0, analysis=True)\n",
    "    gen_df = pd.DataFrame(gen, columns=['gen_SELFIES' if config.use_selfies else 'gen_SMILES'])\n",
    "    print(gen_df)\n",
    "    \n",
    "    if config.use_selfies:\n",
    "        gen_df['gen_SMILES'] = [sf.decoder(x) for x in gen_df['gen_SELFIES']]\n",
    "        mol = gen_df['gen_SELFIES'].apply(Chem.MolFromSmiles)\n",
    "    else:\n",
    "        mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "    qed_list = []\n",
    "    sa_list = []\n",
    "    \n",
    "    for gen_mol in mol.values:\n",
    "        \n",
    "        try:\n",
    "            qed = QED(gen_mol)\n",
    "            sa = SA(gen_mol)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        qed_list.append(qed)\n",
    "        sa_list.append(sa)\n",
    "    \n",
    "    gen_df['gen_qed'] = qed_list\n",
    "    gen_df['gen_SAS'] = sa_list\n",
    "    \n",
    "    obj = 5 * gen_df['gen_qed'] - gen_df['gen_SAS']\n",
    "    print(obj.values)\n",
    "    return z - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining bounds for the hyperparameters\n",
    "pbounds = {'z': (-100, 100)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function(z),\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=2,  # Random exploratory steps\n",
    "    n_iter=10       # Steps of Bayesian Optimization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimizer.max['params']\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with optimized parameters\n",
    "optimized_kernel = C(best_params['C']) * RBF(best_params['RBF_length_scale'])\n",
    "optimized_gp = GaussianProcessRegressor(kernel=optimized_kernel)\n",
    "optimized_gp.fit(GP_train_x, GP_train_y)\n",
    "\n",
    "# Making predictions\n",
    "predictions = optimized_gp.predict(GP_train_x)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Vector Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from viz_utils import slerp, InterpolationLoader, z_to_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'vae_property' # 'vae_property', 'vae'\n",
    "data_type = 'selfies'  # 'selfies'\n",
    "# data_type = 'smiles'\n",
    "steps = 4\n",
    "epoch = 60\n",
    "sample_1 = 3\n",
    "sample_2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_list, y_list, _, train_data, model = InterpolationLoader(dataPATH=\"../moses/dataset/data/ZINC250K/\",\n",
    "                                                    model_type=model_type,\n",
    "                                                    data_type=data_type,\n",
    "                                                    best_epoch=epoch,\n",
    "                                                    i_1=sample_1, i_2=sample_2,\n",
    "                                                    )\n",
    "\n",
    "original_mol = train_data[:,0]\n",
    "\n",
    "interpolated_latents = torch.tensor(np.array([slerp(val, z_list[0,:], z_list[1,:]) for val in np.linspace(0, 1, steps)]))\n",
    "viz_df = z_to_smiles(model, original_mol, interpolated_latents,\n",
    "                     data_type=data_type, steps=steps,\n",
    "                     temp=0.3, argmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'smiles':\n",
    "    result_mol = viz_df['SMILES'].values\n",
    "else:\n",
    "    result_mol = viz_df[\"SELFIES\"].values\n",
    "    \n",
    "result_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'smiles' # 'selfies'\n",
    "# data_type = 'selfies' # 'selfies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/train.csv\")\n",
    "test_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'selfies':\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_selfies\"\n",
    "else:\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_smiles\"\n",
    "\n",
    "    \n",
    "config = torch.load(f'{folder_path}/vae_property_config.pt')\n",
    "vocab = torch.load(f'{folder_path}/vae_property_vocab.pt')\n",
    "\n",
    "print(f\"Use Selfies: {config.use_selfies}\")\n",
    "print(config.reg_prop_tasks)\n",
    "\n",
    "cols = ['SELFIES' if config.use_selfies else 'SMILES', 'logP', 'qed', 'SAS', 'obj']\n",
    "train_data = train_df[cols].values\n",
    "test_data = test_df[cols].values\n",
    "\n",
    "model_path = f'{folder_path}/vae_property_model_080.pt'\n",
    "\n",
    "model = VAEPROPERTY(vocab, config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "trainer = VAEPROPERTYTrainer(config)\n",
    "train_loader = trainer.get_dataloader(model, train_data, shuffle=False)\n",
    "test_loader = trainer.get_dataloader(model, test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(30, 4))\n",
    "\n",
    "for i, epoch in enumerate(['00', 20, 40, 60, 80, 'final']):\n",
    "    \n",
    "    model_path = f'{folder_path}/vae_property_model_0{epoch}.pt'\n",
    "    \n",
    "    if epoch == 'final':\n",
    "        model_path = f'{folder_path}/vae_property_model.pt'\n",
    "        \n",
    "    model = VAEPROPERTY(vocab, config)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    x_list = []\n",
    "    z_list = []\n",
    "    mu_list = []\n",
    "    logvar_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x_list.extend(x)\n",
    "        y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "        mu, logvar, z, _ = model.forward_encoder(x)\n",
    "        z_list.extend(z.detach().cpu().numpy())\n",
    "        mu_list.extend(mu.detach().cpu().numpy())\n",
    "        logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "    viz = PCA(n_components=2)\n",
    "    z_viz = viz.fit_transform(mu_list)\n",
    "    explained_variance = viz.explained_variance_ratio_\n",
    "    print(f\"(Epoch {epoch})Explained variance: {explained_variance}\")\n",
    "    \n",
    "    y_list = np.array(y_list)[:, -1]\n",
    "    \n",
    "    # print(z_viz.shape)\n",
    "    z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "    scatter = axes[i].scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "    axes[i].set_title(f'Epoch {epoch}')\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "    \n",
    "    fig.colorbar(scatter, ax=axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
