{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "import torch\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from moses.vae import VAE\n",
    "from moses.vae_property import VAEPROPERTY\n",
    "from moses.vae.trainer import VAETrainer\n",
    "from moses.vae_property.trainer import VAEPROPERTYTrainer \n",
    "\n",
    "from moses.metrics import QED, SA, logP\n",
    "from moses.utils import get_mol\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import rdBase\n",
    "#from rdkit import RDLogger\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "rdBase.DisableLog('rdApp.*')\n",
    "\n",
    "import selfies as sf\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../checkpoints/opimize_gpr/gpr_fit_ZINC250K_df.csv\")[:1000]\n",
    "test_df = pd.read_csv(\"../checkpoints/opimize_gpr/gpr_test_ZINC250K_df.csv\")\n",
    "start_df = pd.read_csv(\"../checkpoints/opimize_gpr/opt_start_ZINC250K_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_qed = -100\n",
    "nan_sa = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'gpr train: {train_df.shape}')\n",
    "print(f'gpr test: {test_df.shape}')\n",
    "print(f'gpr start: {start_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'smiles'\n",
    "\n",
    "model_name = 'VAEProp_obj_w0.1'\n",
    "folder_path = f\"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_{data_type}\"\n",
    "config = torch.load(f'{folder_path}/vae_property_config.pt')\n",
    "vocab = torch.load(f'{folder_path}/vae_property_vocab.pt')\n",
    "\n",
    "print(f\"Use Selfies: {config.use_selfies}\")\n",
    "print(config.reg_prop_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SELFIES' if config.use_selfies else 'SMILES', 'logP', 'qed', 'SAS', 'obj']\n",
    "train_data = train_df[cols].values\n",
    "test_data = test_df[cols].values\n",
    "start_data = start_df[cols].values\n",
    "\n",
    "\n",
    "model_path = f'{folder_path}/vae_property_model.pt'\n",
    "\n",
    "model = VAEPROPERTY(vocab, config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "trainer = VAEPROPERTYTrainer(config)\n",
    "train_loader = trainer.get_dataloader(model, train_data, shuffle=False)\n",
    "test_loader = trainer.get_dataloader(model, test_data, shuffle=False)\n",
    "start_loader = trainer.get_dataloader(model, start_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x_list = []\n",
    "z_list = []\n",
    "mu_list = []\n",
    "logvar_list = []\n",
    "y_list = []\n",
    "\n",
    "\n",
    "# y_list = y_list.squeeze()\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    x_list.extend(x)\n",
    "    y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "    mu, logvar, z, _ = model.forward_encoder(x)\n",
    "    z_list.extend(z.detach().cpu().numpy())\n",
    "    mu_list.extend(mu.detach().cpu().numpy())\n",
    "    logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "y_list = np.array(y_list).squeeze()\n",
    "GP_train_y = y_list.reshape(-1, y_list.shape[-1])\n",
    "\n",
    "train_data_df = pd.DataFrame(GP_train_y, columns=['logP', 'qed', 'SAS', 'obj'])\n",
    "train_data_df = pd.concat([train_data_df , pd.DataFrame({'z': z_list, 'mu': mu_list, 'logvar': logvar_list})], axis=1)\n",
    "train_data_df.insert(0, 'SELFIES' if config.use_selfies else 'SMILES', [vocab.ids2string(point.cpu().detach().numpy()) for point in x_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_x_list = []\n",
    "test_z_list = []\n",
    "test_mu_list = []\n",
    "test_logvar_list = []\n",
    "test_y_list = []\n",
    "\n",
    "\n",
    "# y_list = y_list.squeeze()\n",
    "\n",
    "for step, batch in enumerate(test_loader):\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    test_x_list.extend(x)\n",
    "    test_y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "    mu, logvar, z, _ = model.forward_encoder(x)\n",
    "    test_z_list.extend(z.detach().cpu().numpy())\n",
    "    test_mu_list.extend(mu.detach().cpu().numpy())\n",
    "    test_logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "test_y_list = np.array(test_y_list).squeeze()\n",
    "GP_test_y = test_y_list.reshape(-1, test_y_list.shape[-1])\n",
    "\n",
    "test_data_df = pd.DataFrame(GP_test_y, columns=['logP', 'qed', 'SAS', 'obj'])\n",
    "test_data_df = pd.concat([test_data_df , pd.DataFrame({'z': test_z_list, 'mu': test_mu_list, 'logvar': test_logvar_list})], axis=1)\n",
    "test_data_df\n",
    "# test_data_df.insert(0, 'SELFIES' if config.use_selfies else 'SMILES', [vocab.ids2string(point.cpu().detach().numpy()) for point in test_x_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_Train_x = torch.tensor(np.array([x for x in train_data_df['z']]))\n",
    "GP_Test_x = torch.tensor(np.array([x for x in test_data_df['z']]))\n",
    "\n",
    "GP_Train_y = np.array([x for x in train_data_df['obj']])\n",
    "GP_Test_y = np.array([x for x in test_data_df['obj']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.sample(len(GP_Train_x), max_len=100, z=GP_Train_x, temp=1.0, test=True)\n",
    "gen_df = pd.DataFrame(gen, columns=['gen_SELFIES' if config.use_selfies else 'gen_SMILES'])\n",
    "\n",
    "if config.use_selfies:\n",
    "    gen_df['gen_SMILES'] = [sf.decoder(x) for x in gen_df['gen_SELFIES']]\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "else:\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "qed_list = []\n",
    "sa_list = []\n",
    "null_cnt = 0\n",
    "\n",
    "for i, gen_mol in enumerate(mol):\n",
    "    if gen_mol is None:\n",
    "        qed_list.append(nan_qed)\n",
    "        sa_list.append(nan_sa)\n",
    "        null_cnt += 1\n",
    "        \n",
    "    else:\n",
    "        qed = QED(gen_mol)\n",
    "        sa = SA(gen_mol)\n",
    "        qed_list.append(qed)\n",
    "        sa_list.append(sa)\n",
    "        \n",
    "gen_df['gen_qed'] = qed_list\n",
    "gen_df['gen_sa'] = sa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Null SMILES: {null_cnt}\")\n",
    "gen_df.gen_SMILES.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "def calculate_qed_sa(z):\n",
    "    gen = model.sample(len(z), max_len=100, z=z, temp=1.0, test=True)\n",
    "    gen_df = pd.DataFrame(gen, columns=['gen_SELFIES' if config.use_selfies else 'gen_SMILES'])\n",
    "\n",
    "    if config.use_selfies:\n",
    "        gen_df['gen_SMILES'] = [sf.decoder(x) for x in gen_df['gen_SELFIES']]\n",
    "        mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "    else:\n",
    "        mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "    qed_list = []\n",
    "    sa_list = []\n",
    "\n",
    "    for i, gen_mol in enumerate(mol):\n",
    "        if gen_mol is None:\n",
    "            qed_list.append(nan_qed)\n",
    "            sa_list.append(nan_sa)\n",
    "            \n",
    "        else:\n",
    "            qed = QED(gen_mol)\n",
    "            sa = SA(gen_mol)\n",
    "            qed_list.append(qed)\n",
    "            sa_list.append(sa)\n",
    "            \n",
    "    gen_df['gen_qed'] = qed_list\n",
    "    gen_df['gen_sa'] = sa_list\n",
    "\n",
    "    return gen_df['gen_qed'].values, gen_df['gen_sa'].values\n",
    "\n",
    "# 목적 함수 정의\n",
    "def objective_function(z):\n",
    "    qed, sa = calculate_qed_sa(z)\n",
    "    return 5 * qed - sa\n",
    "\n",
    "# 초기 데이터 수집\n",
    "def initial_data():\n",
    "    train_z = GP_Train_x\n",
    "    train_y = torch.tensor(5*gen_df['gen_qed'] - gen_df['gen_sa'])\n",
    "    return train_z, train_y.unsqueeze(-1)\n",
    "\n",
    "# GPR 모델 학습\n",
    "def train_gp(train_z, train_y):\n",
    "    gp = SingleTaskGP(train_z, train_y)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return gp\n",
    "\n",
    "# 획득 함수 최적화\n",
    "def optimize_acq(gp, bounds):\n",
    "    acqf = ExpectedImprovement(gp, best_f=train_y.max().item())\n",
    "    new_z, _ = optimize_acqf(acqf, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
    "    \n",
    "    return new_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 데이터\n",
    "train_z, train_y = initial_data()\n",
    "\n",
    "# 초기 설정\n",
    "bounds = torch.stack([torch.full((z.shape[1],), min(train_z.reshape(-1))), torch.full((z.shape[1],), max(train_z.reshape(-1)))]) # to-do : z의 shape에 맞게 수정\n",
    "\n",
    "print(train_z.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "num_iterations = 50\n",
    "new_z_list = []\n",
    "all_z_list = []\n",
    "\n",
    "best_perform = -np.inf\n",
    "\n",
    "for iter in range(num_iterations):\n",
    "    gp = train_gp(train_z, train_y)\n",
    "    new_z = optimize_acq(gp, bounds)\n",
    "\n",
    "    new_y = torch.tensor([objective_function(new_z)])\n",
    "    \n",
    "    if new_y > best_perform:\n",
    "        best_perform = new_y\n",
    "        new_z_list.append(new_z)\n",
    "    \n",
    "    all_z_list.append(new_z)\n",
    "    \n",
    "    # 데이터 업데이트\n",
    "    train_z = torch.cat((train_z, new_z), dim=0)\n",
    "    train_y = torch.cat((train_y, new_y), dim=0)\n",
    "    \n",
    "print(f\"최적의 z index {train_y.argmax()}:\", train_z[train_y.argmax()])\n",
    "print(\"최적의 목적 함수 값:\", train_y.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_z_list = np.array(new_z_list).squeeze()\n",
    "new_z_list.shape\n",
    "\n",
    "all_z_list = np.array(all_z_list).squeeze()\n",
    "all_z_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.sample(len(new_z_list), max_len=100, z=torch.tensor(new_z_list), temp=1.0, test=True)\n",
    "gen_df = pd.DataFrame(gen, columns=['gen_SELFIES' if config.use_selfies else 'gen_SMILES'])\n",
    "\n",
    "if config.use_selfies:\n",
    "    gen_df['gen_SMILES'] = [sf.decoder(x) for x in gen_df['gen_SELFIES']]\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "else:\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "qed_list = []\n",
    "sa_list = []\n",
    "\n",
    "for i, gen_mol in enumerate(mol):\n",
    "    if gen_mol is None:\n",
    "        qed_list.append(0)\n",
    "        sa_list.append(7)\n",
    "        \n",
    "    else:\n",
    "        qed = QED(gen_mol)\n",
    "        sa = SA(gen_mol)\n",
    "        qed_list.append(qed)\n",
    "        sa_list.append(sa)\n",
    "        \n",
    "gen_df['gen_qed'] = qed_list\n",
    "gen_df['gen_sa'] = sa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df['obj'] = 5*gen_df['gen_qed'] - gen_df['gen_sa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(gen_df)), gen_df.obj.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df['RoMol'] = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "if data_type == 'selfies':\n",
    "    display(PandasTools.FrameToGridImage(gen_df, column='RoMol', legendsCol='gen_SELFIES', molsPerRow=4))\n",
    "else:\n",
    "    display(PandasTools.FrameToGridImage(gen_df, column='RoMol', legendsCol='gen_SMILES', molsPerRow=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.sample(len(all_z_list), max_len=100, z=torch.tensor(all_z_list), temp=1.0, test=True)\n",
    "gen_df = pd.DataFrame(gen, columns=['gen_SELFIES' if config.use_selfies else 'gen_SMILES'])\n",
    "\n",
    "if config.use_selfies:\n",
    "    gen_df['gen_SMILES'] = [sf.decoder(x) for x in gen_df['gen_SELFIES']]\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "else:\n",
    "    mol = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "qed_list = []\n",
    "sa_list = []\n",
    "\n",
    "for i, gen_mol in enumerate(mol):\n",
    "    if gen_mol is None:\n",
    "        print(f'Error: {gen_df[\"gen_SMILES\"].iloc[i]}')\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        qed = QED(gen_mol)\n",
    "        sa = SA(gen_mol)\n",
    "        qed_list.append(qed)\n",
    "        sa_list.append(sa)\n",
    "        \n",
    "gen_df['gen_qed'] = qed_list\n",
    "gen_df['gen_sa'] = sa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df['obj'] = 5*gen_df['gen_qed'] - gen_df['gen_sa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(gen_df)), gen_df.obj.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df['RoMol'] = gen_df['gen_SMILES'].apply(Chem.MolFromSmiles)\n",
    "display(PandasTools.FrameToGridImage(gen_df, column='RoMol', legendsCol='gen_SELFIES', molsPerRow=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Vector Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from viz_utils import slerp, InterpolationLoader, z_to_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'vae_property' # 'vae_property', 'vae'\n",
    "data_type = 'selfies'  # 'selfies'\n",
    "# data_type = 'smiles'\n",
    "steps = 4\n",
    "epoch = 60\n",
    "sample_1 = 3\n",
    "sample_2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_list, y_list, _, train_data, model = InterpolationLoader(dataPATH=\"../moses/dataset/data/ZINC250K/\",\n",
    "                                                    model_type=model_type,\n",
    "                                                    data_type=data_type,\n",
    "                                                    best_epoch=epoch,\n",
    "                                                    i_1=sample_1, i_2=sample_2,\n",
    "                                                    )\n",
    "\n",
    "original_mol = train_data[:,0]\n",
    "\n",
    "interpolated_latents = torch.tensor(np.array([slerp(val, z_list[0,:], z_list[1,:]) for val in np.linspace(0, 1, steps)]))\n",
    "viz_df = z_to_smiles(model, original_mol, interpolated_latents,\n",
    "                     data_type=data_type, steps=steps,\n",
    "                     temp=0.3, argmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'smiles':\n",
    "    result_mol = viz_df['SMILES'].values\n",
    "else:\n",
    "    result_mol = viz_df[\"SELFIES\"].values\n",
    "    \n",
    "result_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'smiles' # 'selfies'\n",
    "# data_type = 'selfies' # 'selfies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/train.csv\")\n",
    "test_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'selfies':\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_selfies\"\n",
    "else:\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_smiles\"\n",
    "\n",
    "    \n",
    "config = torch.load(f'{folder_path}/vae_property_config.pt')\n",
    "vocab = torch.load(f'{folder_path}/vae_property_vocab.pt')\n",
    "\n",
    "print(f\"Use Selfies: {config.use_selfies}\")\n",
    "print(config.reg_prop_tasks)\n",
    "\n",
    "cols = ['SELFIES' if config.use_selfies else 'SMILES', 'logP', 'qed', 'SAS', 'obj']\n",
    "train_data = train_df[cols].values\n",
    "test_data = test_df[cols].values\n",
    "\n",
    "model_path = f'{folder_path}/vae_property_model_080.pt'\n",
    "\n",
    "model = VAEPROPERTY(vocab, config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "trainer = VAEPROPERTYTrainer(config)\n",
    "train_loader = trainer.get_dataloader(model, train_data, shuffle=False)\n",
    "test_loader = trainer.get_dataloader(model, test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(30, 4))\n",
    "\n",
    "for i, epoch in enumerate(['00', 20, 40, 60, 80, 'final']):\n",
    "    \n",
    "    model_path = f'{folder_path}/vae_property_model_0{epoch}.pt'\n",
    "    \n",
    "    if epoch == 'final':\n",
    "        model_path = f'{folder_path}/vae_property_model.pt'\n",
    "        \n",
    "    model = VAEPROPERTY(vocab, config)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    x_list = []\n",
    "    z_list = []\n",
    "    mu_list = []\n",
    "    logvar_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x_list.extend(x)\n",
    "        y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "        mu, logvar, z, _ = model.forward_encoder(x)\n",
    "        z_list.extend(z.detach().cpu().numpy())\n",
    "        mu_list.extend(mu.detach().cpu().numpy())\n",
    "        logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "    viz = PCA(n_components=2)\n",
    "    z_viz = viz.fit_transform(mu_list)\n",
    "    explained_variance = viz.explained_variance_ratio_\n",
    "    print(f\"(Epoch {epoch})Explained variance: {explained_variance}\")\n",
    "    \n",
    "    y_list = np.array(y_list)[:, -1]\n",
    "    \n",
    "    # print(z_viz.shape)\n",
    "    z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "    scatter = axes[i].scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "    axes[i].set_title(f'Epoch {epoch}')\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "    \n",
    "    fig.colorbar(scatter, ax=axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
