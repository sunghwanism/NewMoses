{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "from moses.vae import VAE\n",
    "from moses.vae_property import VAEPROPERTY\n",
    "from moses.vae.trainer import VAETrainer\n",
    "from moses.vae_property.trainer import VAEPROPERTYTrainer \n",
    "\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.*')\n",
    "import selfies as sf\n",
    "\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from viz_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_qed = 0\n",
    "nan_sa = 5\n",
    "num_iterations = 50\n",
    "\n",
    "data_type = 'selfies'\n",
    "model_name = 'vae_property_obj_proploss_w0.1' # 'vae_property_obj_w0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_type in ['smiles', 'selfies']:\n",
    "    for sample_num in [2000]:\n",
    "        (GP_Train_x, GP_Train_y, \n",
    "        GP_Test_x, GP_Test_y, \n",
    "        train_data_df, test_data_df, \n",
    "        model, vocab, config) = ready_gpr(sample_num, data_type=data_type, model_name=model_name)\n",
    "        \n",
    "        \n",
    "        for rp in tqdm(range(6)):\n",
    "            # 초기 데이터\n",
    "            train_z, train_y = initial_data(GP_Train_x, GP_Train_y)\n",
    "\n",
    "            # 초기 설정\n",
    "            bounds = torch.stack([torch.full((train_z.shape[1],), min(train_z.reshape(-1))),\n",
    "                                torch.full((train_z.shape[1],), max(train_z.reshape(-1)))])\n",
    "\n",
    "            best_z_list = []\n",
    "            all_z_list = []\n",
    "            new_z_step = []\n",
    "\n",
    "            best_z_list_idx = []\n",
    "            step_list = []\n",
    "\n",
    "            best_perform = -np.inf\n",
    "            save_epoch = 40\n",
    "\n",
    "            for iter in range(num_iterations):\n",
    "                gp = train_gp(train_z, train_y)\n",
    "                new_z = optimize_acq(gp, bounds, train_y)\n",
    "                new_y = torch.tensor([objective_function(model, config, nan_qed, nan_sa, new_z,\n",
    "                                                        temp=1.0, test=True)])\n",
    "                \n",
    "                if new_y > best_perform:\n",
    "                    best_perform = new_y\n",
    "                    best_z_list.append(new_z)\n",
    "                    best_z_list_idx.append(iter)\n",
    "                    print(\"New best z found at iter\", iter, \":\", \"y:\", round(float(new_y), 2))\n",
    "                    \n",
    "                if iter % save_epoch == 0:\n",
    "                    new_z_step.append(new_z)\n",
    "                    step_list.append(iter)\n",
    "                \n",
    "                if iter == num_iterations-1:\n",
    "                    best_z_list.append(new_z)\n",
    "                    best_z_list_idx.append(iter)\n",
    "                    new_z_step.append(new_z)\n",
    "                    step_list.append(iter)\n",
    "                \n",
    "                all_z_list.append(new_z)\n",
    "                \n",
    "                # 데이터 업데이트\n",
    "                train_z = torch.cat((train_z, new_z), dim=0)\n",
    "                train_y = torch.cat((train_y, new_y), dim=0)\n",
    "                \n",
    "            best_z_list = reshape_z(best_z_list)\n",
    "            new_z_step = reshape_z(new_z_step)\n",
    "            all_z_list = reshape_z(all_z_list)\n",
    "            \n",
    "            \n",
    "            best_df = generate_df(best_z_list, best_z_list_idx, model, config, nan_qed, nan_sa, \n",
    "                                  temp=1.0, test=True)\n",
    "            best_df.to_csv(f\"./repeat/rp{rp}/vae_prop_{data_type}_best_n{sample_num}_ep{num_iterations}_rp{rp}.csv\", index=False)\n",
    "            \n",
    "            \n",
    "            all_df = generate_df(all_z_list, range(len(all_z_list)), model, config, nan_qed, nan_sa, \n",
    "                                 temp=1.0, test=True)\n",
    "            all_df.to_csv(f\"./repeat/rp{rp}/vae_prop_{data_type}_all_n{sample_num}_ep{num_iterations}_rp{rp}.csv\", index=False)\n",
    "            \n",
    "            \n",
    "            step_df = generate_df(new_z_step, step_list, model, config, nan_qed, nan_sa, temp=1.0, test=True)\n",
    "\n",
    "            step_df.to_csv(f\"./repeat/rp{rp}/vae_prop_{data_type}_step40_n{sample_num}_ep{num_iterations}_rp{rp}.csv\", index=False)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 1000\n",
    "num_iterations = 50\n",
    "nan_qed = 0\n",
    "nan_sa = 10\n",
    "\n",
    "data_type ='selfies'\n",
    "model_name = 'vae_property_obj_proploss_w0.1' # 'vae_property_obj_w0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(GP_Train_x, GP_Train_y, \n",
    " GP_Test_x, GP_Test_y, \n",
    " train_data_df, test_data_df, \n",
    " model, vocab, config) = ready_gpr(sample_num, data_type=data_type, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 초기 데이터\n",
    "train_z, train_y = initial_data(GP_Train_x, GP_Train_y)\n",
    "\n",
    "# 초기 설정\n",
    "bounds = torch.stack([torch.full((train_z.shape[1],), min(train_z.reshape(-1))),\n",
    "                      torch.full((train_z.shape[1],), max(train_z.reshape(-1)))])\n",
    "\n",
    "best_z_list = []\n",
    "all_z_list = []\n",
    "new_z_step = []\n",
    "\n",
    "best_z_list_idx = []\n",
    "step_list = []\n",
    "\n",
    "best_perform = -np.inf\n",
    "save_epoch = 40\n",
    "\n",
    "for iter in tqdm(range(num_iterations)):\n",
    "    gp = train_gp(train_z, train_y)\n",
    "    new_z = optimize_acq(gp, bounds, train_y)\n",
    "    new_y = torch.tensor([objective_function(model, config, nan_qed, nan_sa, new_z,\n",
    "                                             temp=1.0, test=True)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if new_y > best_perform:\n",
    "        best_perform = new_y\n",
    "        best_z_list.append(new_z)\n",
    "        best_z_list_idx.append(iter)\n",
    "        print(\"New best z found at iter\", iter, \":\", \"y:\", round(float(new_y), 2))\n",
    "        \n",
    "    if iter % save_epoch == 0:\n",
    "        new_z_step.append(new_z)\n",
    "        step_list.append(iter)\n",
    "    \n",
    "    if iter == num_iterations-1:\n",
    "        best_z_list.append(new_z)\n",
    "        best_z_list_idx.append(iter)\n",
    "        new_z_step.append(new_z)\n",
    "        step_list.append(iter)\n",
    "    \n",
    "    all_z_list.append(new_z)\n",
    "    \n",
    "    # 데이터 업데이트\n",
    "    train_z = torch.cat((train_z, new_z), dim=0)\n",
    "    train_y = torch.cat((train_y, new_y), dim=0)\n",
    "    \n",
    "print(f\"최적의 z index {train_y.argmax()}:\", train_z[train_y.argmax()])\n",
    "print(\"최적의 목적 함수 값:\", train_y.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_z_list = reshape_z(best_z_list)\n",
    "new_z_step = reshape_z(new_z_step)\n",
    "all_z_list = reshape_z(all_z_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = generate_df(best_z_list, best_z_list_idx, model, config, nan_qed, nan_sa, \n",
    "                      temp=1.0, test=True)\n",
    "\n",
    "best_df.to_csv(f\"./after_optim/vae_prop_{data_type}_best_n{sample_num}_ep{num_iterations}.csv\", index=False)\n",
    "# best_df.to_csv(f\"./after_optim/vae_{data_type}_best_n{sample_num}_ep{num_iterations}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualizeMol(best_df, data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(best_z_list_idx, best_df.obj.values)\n",
    "plt.title('Updated Objective Function with Best Value')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function')\n",
    "plt.xticks(best_z_list_idx, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz = PCA(n_components=2)\n",
    "# z_viz = viz.fit_transform(train_z[:500])\n",
    "# y_list = np.array(train_y[:500])\n",
    "\n",
    "# explained_variance = viz.explained_variance_ratio_\n",
    "# z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "# scatter = plt.scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "# new_z_viz = viz.transform(new_z_list)\n",
    "# new_y_list = np.array(train_y[500:])\n",
    "# new_z_viz = MinMaxScaler().fit_transform(new_z_viz)\n",
    "# plt.scatter(new_z_viz[:, 0], new_z_viz[:, 1], c=new_y_list, marker='x', s=50, alpha=1, edgecolors='none')\n",
    "\n",
    "# plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All z reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = generate_df(all_z_list, range(len(all_z_list)), model, config, nan_qed, nan_sa, \n",
    "                      temp=1.0, test=True)\n",
    "\n",
    "all_df.to_csv(f\"./after_optim/vae_prop_{data_type}_all_n{sample_num}_ep{num_iterations}.csv\", index=False)\n",
    "# best_df.to_csv(f\"./after_optim/vae_{data_type}_all_n{sample_num}_ep{num_iterations}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(range(len(all_z_list)), all_df.obj.values)\n",
    "plt.title('Objective function with all iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function')\n",
    "plt.xticks(range(len(all_z_list), 2), fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualizeMol(all_df, data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz = PCA(n_components=2)\n",
    "# z_viz = viz.fit_transform(train_z[:500])\n",
    "# y_list = np.array(train_y[:500])\n",
    "\n",
    "# explained_variance = viz.explained_variance_ratio_\n",
    "# z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "# scatter = plt.scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "# new_z_viz = viz.transform(new_z_list)\n",
    "# new_y_list = np.array(train_y[500:])\n",
    "# new_z_viz = MinMaxScaler().fit_transform(new_z_viz)\n",
    "# plt.scatter(new_z_viz[:, 0], new_z_viz[:, 1], c=new_y_list, marker='x', s=50, alpha=1, edgecolors='none')\n",
    "\n",
    "# plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz fer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_df = generate_df(new_z_step, step_list, model, config, nan_qed, nan_sa, \n",
    "                      temp=1.0, test=True)\n",
    "\n",
    "step_df.to_csv(f\"./after_optim/vae_prop_{data_type}_step40_n{sample_num}_ep{num_iterations}.csv\", index=False)\n",
    "# best_df.to_csv(f\"./after_optim/vae_{data_type}_step40_n{sample_num}_ep{num_iterations}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(step_list, step_df.obj.values)\n",
    "plt.title('Objective function with all iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Function')\n",
    "plt.xticks(step_list, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualizeMol(step_df, data_type=data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz = PCA(n_components=2)\n",
    "# z_viz = viz.fit_transform(train_z[:500])\n",
    "# y_list = np.array(train_y[:500])\n",
    "\n",
    "# explained_variance = viz.explained_variance_ratio_\n",
    "# z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "# scatter = plt.scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "# new_z_viz = viz.transform(new_z_list)\n",
    "# new_y_list = np.array(train_y[500:])\n",
    "# new_z_viz = MinMaxScaler().fit_transform(new_z_viz)\n",
    "# plt.scatter(new_z_viz[:, 0], new_z_viz[:, 1], c=new_y_list, marker='x', s=50, alpha=1, edgecolors='none')\n",
    "\n",
    "# plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Vector Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from viz_utils import slerp, InterpolationLoader, z_to_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'vae_property' # 'vae_property', 'vae'\n",
    "model_type = 'vae' # 'vae_property', 'vae'\n",
    "data_type = 'selfies'  # 'selfies'\n",
    "# data_type = 'smiles'\n",
    "steps = 4\n",
    "epoch = 60\n",
    "sample_1 = 3\n",
    "sample_2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_list, y_list, _, train_data, model = InterpolationLoader(dataPATH=\"../moses/dataset/data/ZINC250K/\",\n",
    "                                                    model_type=model_type,\n",
    "                                                    data_type=data_type,\n",
    "                                                    best_epoch=epoch,\n",
    "                                                    i_1=sample_1, i_2=sample_2,\n",
    "                                                    )\n",
    "\n",
    "original_mol = train_data[:,0]\n",
    "\n",
    "interpolated_latents = torch.tensor(np.array([slerp(val, z_list[0,:], z_list[1,:]) for val in np.linspace(0, 1, steps)]))\n",
    "viz_df = z_to_smiles(model, original_mol, interpolated_latents,\n",
    "                     data_type=data_type, steps=steps,\n",
    "                     temp=0.3, argmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == 'smiles':\n",
    "    result_mol = viz_df['SMILES'].values\n",
    "else:\n",
    "    result_mol = viz_df[\"SELFIES\"].values\n",
    "    \n",
    "result_mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'smiles' # 'selfies'\n",
    "# data_type = 'selfies' # 'selfies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/train.csv\")\n",
    "test_df = pd.read_csv(\"../moses/dataset/data/ZINC250K/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data_type == 'selfies':\n",
    "#     folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_selfies\"\n",
    "# else:\n",
    "    # folder_path = \"../checkpoints/ZINC250K_vae_property_obj_proploss_w0.1_smiles\"\n",
    "    \n",
    "if data_type == 'selfies':\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_selfies\"\n",
    "else:\n",
    "    folder_path = \"../checkpoints/ZINC250K_vae_smiles\"\n",
    "\n",
    "    \n",
    "# config = torch.load(f'{folder_path}/vae_property_config.pt')\n",
    "# vocab = torch.load(f'{folder_path}/vae_property_vocab.pt')\n",
    "\n",
    "config = torch.load(f'{folder_path}/vae_config.pt')\n",
    "vocab = torch.load(f'{folder_path}/vae_vocab.pt')\n",
    "\n",
    "if data_type == 'selfies':\n",
    "    print(f\"Use Selfies: {config.use_selfies}\")\n",
    "    print(config.reg_prop_tasks)\n",
    "\n",
    "cols = ['SELFIES' if config.use_selfies else 'SMILES', 'logP', 'qed', 'SAS', 'obj']\n",
    "train_data = train_df[cols].values\n",
    "test_data = test_df[cols].values\n",
    "\n",
    "# model_path = f'{folder_path}/vae_property_model_080.pt'\n",
    "# model = VAEPROPERTY(vocab, config)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# trainer = VAEPROPERTYTrainer(config)\n",
    "\n",
    "model_path = f'{folder_path}/vae_model.pt'\n",
    "\n",
    "model = VAE(vocab, config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "trainer = VAETrainer(config)\n",
    "\n",
    "\n",
    "train_loader = trainer.get_dataloader(model, train_data, shuffle=False)\n",
    "test_loader = trainer.get_dataloader(model, test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(30, 4))\n",
    "\n",
    "for i, epoch in enumerate(['00', 20, 40, 60, 80, 'final']):\n",
    "    \n",
    "    # model_path = f'{folder_path}/vae_property_model_0{epoch}.pt'\n",
    "    model_path = f'{folder_path}/vae_model_0{epoch}.pt'\n",
    "    \n",
    "    if epoch == 'final':\n",
    "        model_path = f'{folder_path}/vae_property_model.pt'\n",
    "        \n",
    "    # model = VAEPROPERTY(vocab, config)\n",
    "    # model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model = VAE(vocab, config)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    x_list = []\n",
    "    z_list = []\n",
    "    mu_list = []\n",
    "    logvar_list = []\n",
    "    y_list = []\n",
    "\n",
    "    # for step, batch in enumerate(train_loader):\n",
    "    #     x = batch[0]\n",
    "    #     y = batch[1]\n",
    "    #     x_list.extend(x)\n",
    "    #     y_list.extend(np.array(y).squeeze())\n",
    "\n",
    "    #     mu, logvar, z, _ = model.forward_encoder(x)\n",
    "    #     z_list.extend(z.detach().cpu().numpy())\n",
    "    #     mu_list.extend(mu.detach().cpu().numpy())\n",
    "    #     logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        \n",
    "        x_list.extend(batch)\n",
    "        # y_list.extend(np.array(batch[-1]).squeeze())\n",
    "\n",
    "        mu, logvar, z, _ = model.forward_encoder(batch)\n",
    "        z_list.extend(z.detach().cpu().numpy())\n",
    "        mu_list.extend(mu.detach().cpu().numpy())\n",
    "        logvar_list.extend(logvar.detach().cpu().numpy())\n",
    "\n",
    "    viz = PCA(n_components=2)\n",
    "    z_viz = viz.fit_transform(mu_list)\n",
    "    explained_variance = viz.explained_variance_ratio_\n",
    "    print(f\"(Epoch {epoch})Explained variance: {explained_variance}\")\n",
    "    \n",
    "    y_list = np.array(y_list)[:, -1]\n",
    "    \n",
    "    # print(z_viz.shape)\n",
    "    z_viz = MinMaxScaler().fit_transform(z_viz)\n",
    "\n",
    "    scatter = axes[i].scatter(z_viz[:, 0], z_viz[:, 1], c=y_list, cmap='viridis', marker='.', s=10, alpha=0.5, edgecolors='none')\n",
    "\n",
    "    axes[i].set_title(f'Epoch {epoch}')\n",
    "    axes[i].set_xlabel('PC1')\n",
    "    axes[i].set_ylabel('PC2')\n",
    "    \n",
    "    fig.colorbar(scatter, ax=axes[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'selfies' # 'smiles', 'selfies\n",
    "n_sample = 1000\n",
    "n_epoch = 200\n",
    "df = pd.read_csv(\"../moses/dataset/data/ZINC250K/train.csv\")\n",
    "gen_df = pd.read_csv(f\"./after_optim/vae_prop_{data_type}_best_n{n_sample}_ep{n_epoch}.csv\")\n",
    "all_df = pd.read_csv(f\"./after_optim/vae_prop_{data_type}_all_n{n_sample}_ep{n_epoch}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_latent_with_optim(df, gen_df, all_df, data_type=data_type, model_type='vae_property',\n",
    "                      base_pca='mu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_latent_with_optim(df, gen_df, all_df, data_type=data_type, model_type='vae_property',\n",
    "                      base_pca='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
